{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest: Out-of-Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'la'\n",
    "nb = 'zipcode'\n",
    "file = '../../Data/data_'+city+'.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "68\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "data = data[data['disadvantaged']==True]\n",
    "print(len(data))\n",
    "data = data[data['count_listings']>=5]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bedrooms_log</th>\n",
       "      <th>beds</th>\n",
       "      <th>beds_log</th>\n",
       "      <th>person_capacity</th>\n",
       "      <th>person_capacity_log</th>\n",
       "      <th>price</th>\n",
       "      <th>price_log</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>t2_index</th>\n",
       "      <th>t1_index_perc</th>\n",
       "      <th>t2_index_perc</th>\n",
       "      <th>age_change</th>\n",
       "      <th>income_change</th>\n",
       "      <th>house_change</th>\n",
       "      <th>edu_change</th>\n",
       "      <th>index_change</th>\n",
       "      <th>disadvantaged</th>\n",
       "      <th>gentrifying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90021.0</td>\n",
       "      <td>1.019417</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>1.623188</td>\n",
       "      <td>0.484392</td>\n",
       "      <td>4.719807</td>\n",
       "      <td>1.551768</td>\n",
       "      <td>189.835749</td>\n",
       "      <td>5.246159</td>\n",
       "      <td>4.612069</td>\n",
       "      <td>...</td>\n",
       "      <td>6.578947</td>\n",
       "      <td>3.508772</td>\n",
       "      <td>2.807018</td>\n",
       "      <td>-29.122807</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>-9.473684</td>\n",
       "      <td>-0.701754</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90019.0</td>\n",
       "      <td>1.262758</td>\n",
       "      <td>0.233298</td>\n",
       "      <td>1.941368</td>\n",
       "      <td>0.663393</td>\n",
       "      <td>3.388949</td>\n",
       "      <td>1.220520</td>\n",
       "      <td>106.390033</td>\n",
       "      <td>4.667112</td>\n",
       "      <td>4.701550</td>\n",
       "      <td>...</td>\n",
       "      <td>49.824561</td>\n",
       "      <td>36.491228</td>\n",
       "      <td>48.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.824561</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>11.929825</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90026.0</td>\n",
       "      <td>1.239836</td>\n",
       "      <td>0.214979</td>\n",
       "      <td>1.602360</td>\n",
       "      <td>0.471478</td>\n",
       "      <td>3.049864</td>\n",
       "      <td>1.115097</td>\n",
       "      <td>119.938350</td>\n",
       "      <td>4.786978</td>\n",
       "      <td>4.780980</td>\n",
       "      <td>...</td>\n",
       "      <td>58.421053</td>\n",
       "      <td>31.228070</td>\n",
       "      <td>64.210526</td>\n",
       "      <td>9.122807</td>\n",
       "      <td>23.859649</td>\n",
       "      <td>17.894737</td>\n",
       "      <td>23.508772</td>\n",
       "      <td>32.982456</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90028.0</td>\n",
       "      <td>1.039799</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>1.833959</td>\n",
       "      <td>0.606477</td>\n",
       "      <td>3.533396</td>\n",
       "      <td>1.262259</td>\n",
       "      <td>128.209114</td>\n",
       "      <td>4.853663</td>\n",
       "      <td>4.620887</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>41.052632</td>\n",
       "      <td>60.701754</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>7.719298</td>\n",
       "      <td>12.631579</td>\n",
       "      <td>15.087719</td>\n",
       "      <td>19.649123</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90042.0</td>\n",
       "      <td>1.283582</td>\n",
       "      <td>0.249655</td>\n",
       "      <td>1.635514</td>\n",
       "      <td>0.491957</td>\n",
       "      <td>3.097015</td>\n",
       "      <td>1.130439</td>\n",
       "      <td>100.479478</td>\n",
       "      <td>4.609954</td>\n",
       "      <td>4.835385</td>\n",
       "      <td>...</td>\n",
       "      <td>48.070175</td>\n",
       "      <td>32.280702</td>\n",
       "      <td>44.736842</td>\n",
       "      <td>10.175439</td>\n",
       "      <td>5.964912</td>\n",
       "      <td>6.315789</td>\n",
       "      <td>7.368421</td>\n",
       "      <td>12.456140</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    zipcode  bedrooms  bedrooms_log      beds  beds_log  person_capacity  \\\n",
       "8   90021.0  1.019417      0.019231  1.623188  0.484392         4.719807   \n",
       "10  90019.0  1.262758      0.233298  1.941368  0.663393         3.388949   \n",
       "14  90026.0  1.239836      0.214979  1.602360  0.471478         3.049864   \n",
       "15  90028.0  1.039799      0.039028  1.833959  0.606477         3.533396   \n",
       "16  90042.0  1.283582      0.249655  1.635514  0.491957         3.097015   \n",
       "\n",
       "    person_capacity_log       price  price_log  star_rating  ...   t2_index  \\\n",
       "8              1.551768  189.835749   5.246159     4.612069  ...   6.578947   \n",
       "10             1.220520  106.390033   4.667112     4.701550  ...  49.824561   \n",
       "14             1.115097  119.938350   4.786978     4.780980  ...  58.421053   \n",
       "15             1.262259  128.209114   4.853663     4.620887  ...  55.000000   \n",
       "16             1.130439  100.479478   4.609954     4.835385  ...  48.070175   \n",
       "\n",
       "    t1_index_perc  t2_index_perc  age_change  income_change  house_change  \\\n",
       "8        3.508772       2.807018  -29.122807       0.701754      0.350877   \n",
       "10      36.491228      48.421053    0.000000       9.824561      6.666667   \n",
       "14      31.228070      64.210526    9.122807      23.859649     17.894737   \n",
       "15      41.052632      60.701754    0.350877       7.719298     12.631579   \n",
       "16      32.280702      44.736842   10.175439       5.964912      6.315789   \n",
       "\n",
       "    edu_change  index_change  disadvantaged  gentrifying  \n",
       "8    -9.473684     -0.701754           True        False  \n",
       "10   10.526316     11.929825           True         True  \n",
       "14   23.508772     32.982456           True         True  \n",
       "15   15.087719     19.649123           True         True  \n",
       "16    7.368421     12.456140           True         True  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = [\n",
    "'bedrooms','price','star_rating','review_rating_location',\n",
    "'count_listings',\n",
    "'count_reviews',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_all = [\n",
    "'review_len',\n",
    "'location_words_perc','sent_comp','sent_comp_location',\n",
    "'dtv_1', 'dtv_2', 'dtv_3', 'dtv_4', 'dtv_5', 'dtv_6', 'dtv_7', 'dtv_8', 'dtv_9', 'dtv_10', 'dtv_11', 'dtv_12', 'dtv_13', 'dtv_14', 'dtv_15', 'dtv_16', 'dtv_17', 'dtv_18', 'dtv_19', 'dtv_20', 'dtv_21', 'dtv_22', 'dtv_23', 'dtv_24', 'dtv_25',\n",
    "'lda_1', 'lda_2', 'lda_3', 'lda_4', 'lda_5',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_base = [\n",
    "'review_len',\n",
    "'location_words_perc','sent_comp','sent_comp_location',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2(r2, shape):\n",
    "    n = shape[0]\n",
    "    p = shape[1]\n",
    "    \n",
    "    ar2 = 1-((1-r2)*((n-1)/(n-p-1)))\n",
    "    return ar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r2(pred, real):\n",
    "    pred = np.array(pred)\n",
    "    real = np.array(real)\n",
    "    \n",
    "    y_bar = np.mean(real)\n",
    "    ss_total = np.sum(np.square(real-y_bar))\n",
    "    ss_res = np.sum(np.square(real-pred))\n",
    "    \n",
    "    return 1 - (ss_res/ss_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(key, X, y, parameters,chosen):\n",
    "    base = RandomForestRegressor(max_features='sqrt')\n",
    "    grid = GridSearchCV(base, parameters, cv=3)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    best = grid.best_params_\n",
    "    for k,v in best.items():\n",
    "        chosen[key][k].append(v)\n",
    "\n",
    "    reg = RandomForestRegressor(n_estimators=best['n_estimators'], max_depth=best['max_depth'], max_features='sqrt')\n",
    "    reg.fit(X, y)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(key, reg, X, y, mae, mse, r2, importance):\n",
    "    test_r2[key].append(reg.score(X, y))\n",
    "    test_mae[key].append(mean_absolute_error(reg.predict(X), y))\n",
    "    test_mse[key].append(mean_squared_error(reg.predict(X), y))\n",
    "    importance[key][:,i] = reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_dtv(X,y):\n",
    "    scores = {}\n",
    "    for i in range(1,26):\n",
    "        f = 'dtv_'+str(i)\n",
    "        scores[f] = abs(stats.pearsonr(X[f], y)[0])\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return list(scores.keys())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_lda(X,y):\n",
    "    scores = {}\n",
    "    for i in range(1,6):\n",
    "        f = 'lda_'+str(i)\n",
    "        scores[f] = abs(stats.pearsonr(X[f], y)[0])\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return list(scores.keys())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VIF_scores(X):\n",
    "    scores = {}\n",
    "    for c in X.columns:\n",
    "        X_temp = X.drop(columns=c)\n",
    "        reg = LinearRegression().fit(X_temp, X[c])\n",
    "        r2 = reg.score(X_temp, X[c])\n",
    "        if r2 != 1:\n",
    "            scores[c] = 1/(1-r2)\n",
    "        else:\n",
    "            scores[c] = np.inf\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VIF_high(X):\n",
    "    for c in X.columns:\n",
    "        X_temp = X.drop(columns=c)\n",
    "        reg = LinearRegression().fit(X_temp, X[c])\n",
    "        r2 = reg.score(X_temp, X[c])\n",
    "        if r2 != 1:\n",
    "            score = 1/(1-r2)\n",
    "            if score>=5:\n",
    "                return True\n",
    "        else:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:08<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "pred = 'index_change'\n",
    "trials = 100\n",
    "\n",
    "dtv_keep = 5\n",
    "lda_keep = 5\n",
    "\n",
    "test_mae = {'base':[], 'sf':[], 'uf': [], 'all':[]}\n",
    "test_mse = {'base':[], 'sf':[], 'uf': [], 'all':[]}\n",
    "test_r2 = {'base':[], 'sf':[], 'uf': [], 'all':[]}\n",
    "\n",
    "\n",
    "importance = {'sf':np.zeros((len(sf),trials)), 'uf':np.zeros((len(uf_base)+dtv_keep+lda_keep,trials)), 'all':np.zeros((len(sf)+len(uf_base)+dtv_keep+lda_keep,trials))}\n",
    "\n",
    "parameters = {'n_estimators':[100],'max_depth': [None]}\n",
    "chosen = {'sf':{},'uf':{},'all':{}}\n",
    "\n",
    "for p in parameters.keys():\n",
    "    for i in chosen.keys():\n",
    "        chosen[i][p] = []\n",
    "\n",
    "for i in tqdm(range(trials)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[sf+uf_all], data[pred], test_size=1/2, shuffle=True)\n",
    "    \n",
    "    # Choose Top LDA and D2V\n",
    "    dtv_ranked = top_dtv(X_train,y_train)\n",
    "    dtv = []\n",
    "    for f in dtv_ranked:\n",
    "        dtv.append(f)\n",
    "        if len(dtv)>=dtv_keep:\n",
    "            break\n",
    "    \n",
    "    lda_ranked = top_lda(X_train,y_train)\n",
    "    lda = []\n",
    "    for f in lda_ranked:\n",
    "        lda.append(f)\n",
    "        if len(lda)>=lda_keep:\n",
    "            break\n",
    "\n",
    "    uf = uf_base + dtv + lda\n",
    "    \n",
    "    X_train_sf = X_train[sf]\n",
    "    X_train_uf = X_train[uf]\n",
    "    X_test_sf = X_test[sf]\n",
    "    X_test_uf = X_test[uf]\n",
    "    X_train = X_train[sf+uf]\n",
    "    X_test = X_test[sf+uf]\n",
    "    \n",
    "    # Baseline\n",
    "    base = [0]*len(y_test)\n",
    "    test_r2['base'].append(calculate_r2(base, y_test))\n",
    "    test_mae['base'].append(mean_absolute_error(base, y_test))\n",
    "    test_mse['base'].append(mean_squared_error(base, y_test))\n",
    "    \n",
    "    # Structured Features\n",
    "    reg = model('sf', X_train_sf, y_train, parameters, chosen)\n",
    "    update('sf', reg, X_test_sf, y_test, test_mae, test_mse, test_r2, importance)\n",
    "    \n",
    "    # Unstructured Features\n",
    "    reg = model('uf', X_train_uf, y_train, parameters, chosen)\n",
    "    update('uf', reg, X_test_uf, y_test, test_mae, test_mse, test_r2, importance)\n",
    "\n",
    "    # All Features\n",
    "    reg = model('all', X_train, y_train, parameters, chosen)\n",
    "    update('all', reg, X_test, y_test, test_mae, test_mse, test_r2, importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "-0.1882210400321788 0.07536644091541186\n",
      "9.385783424077434 1.6602562382312522\n",
      "14.98540776830452 4.1624636069856935\n",
      "\n",
      "sf\n",
      "-0.04947393208739757 0.3303327877750238 -0.33569409538396044\n",
      "8.26008166969147 1.2919231472286308\n",
      "13.848551434338829 3.871533941087701\n",
      "\n",
      "uf\n",
      "0.004307130857802456 0.30841183208290834 -0.9913857382843951\n",
      "9.096280096793711 1.320525555053482\n",
      "13.244032135769764 2.9055311907395556\n",
      "\n",
      "all\n",
      "0.05313570104966775 0.23357615088210862 -2.3140250463261625\n",
      "8.45865638233515 1.2798567536282877\n",
      "13.174715883380367 3.475637980642623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in ['base', 'sf', 'uf', 'all']:\n",
    "    print(k)\n",
    "    if k != 'base':\n",
    "        print(np.mean(test_r2[k]), np.std(test_r2[k]), adjusted_r2(np.mean(test_r2[k]), (len(data)/2, importance[k].shape[0])))\n",
    "    else:\n",
    "        print(np.mean(test_r2[k]), np.std(test_r2[k]))       \n",
    "    print(np.mean(test_mae[k]), np.std(test_mae[k]))\n",
    "    print(np.mean(np.sqrt(test_mse[k])),np.std(np.sqrt(test_mse[k])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf\n",
      "                  feature  importance       std\n",
      "4          count_listings    0.250006  0.036324\n",
      "5           count_reviews    0.217429  0.035269\n",
      "3  review_rating_location    0.165038  0.051945\n",
      "0                bedrooms    0.157711  0.062293\n",
      "1                   price    0.111544  0.022603\n",
      "2             star_rating    0.098271  0.022127\n",
      "uf\n",
      "                feature  importance       std\n",
      "4                 dtv_0    0.098327  0.023616\n",
      "9                 lda_0    0.092296  0.029898\n",
      "5                 dtv_1    0.090497  0.024179\n",
      "6                 dtv_2    0.085103  0.021580\n",
      "8                 dtv_4    0.084231  0.026422\n",
      "1   location_words_perc    0.081644  0.025609\n",
      "3    sent_comp_location    0.080965  0.025843\n",
      "7                 dtv_3    0.079869  0.025354\n",
      "10                lda_1    0.079156  0.024612\n",
      "11                lda_2    0.052389  0.015801\n",
      "all\n",
      "                   feature  importance       std\n",
      "4           count_listings    0.114896  0.028238\n",
      "5            count_reviews    0.100335  0.027929\n",
      "3   review_rating_location    0.075239  0.030377\n",
      "10                   dtv_0    0.063376  0.020947\n",
      "11                   dtv_1    0.060440  0.021683\n",
      "12                   dtv_2    0.056141  0.020724\n",
      "15                   lda_0    0.056104  0.020859\n",
      "14                   dtv_4    0.052564  0.023993\n",
      "9       sent_comp_location    0.052155  0.024309\n",
      "13                   dtv_3    0.050563  0.020539\n"
     ]
    }
   ],
   "source": [
    "for k in ['sf', 'uf', 'all']:\n",
    "    if k == 'sf':\n",
    "        features = sf\n",
    "    elif k == 'uf':\n",
    "        features = uf_base.copy()\n",
    "        for i in range(dtv_keep):\n",
    "            features.append('dtv_'+str(i))\n",
    "        for i in range(lda_keep):\n",
    "            features.append('lda_'+str(i))\n",
    "    elif k == 'all':\n",
    "        features = sf + uf_base.copy()\n",
    "        for i in range(dtv_keep):\n",
    "            features.append('dtv_'+str(i))\n",
    "        for i in range(lda_keep):\n",
    "            features.append('lda_'+str(i))\n",
    "        \n",
    "    df = {'feature':[], 'importance':[], 'std':[]}\n",
    "    for i,f in enumerate(features):\n",
    "        df['feature'].append(f)\n",
    "        df['importance'].append(np.mean(importance[k][i, :]))\n",
    "        df['std'].append(np.std(importance[k][i, :]))\n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    df = df.sort_values(by=['importance'], ascending=False)\n",
    "    print(k)\n",
    "    print(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

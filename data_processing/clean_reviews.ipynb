{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: clean_reviews.ipynb -- Preprocessing Script for Review Text\n",
    "# Author: Shomik Jain\n",
    "# Date: 2/02/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'nyc_reviews.tsv'\n",
    "data = pd.read_csv(file, delimiter='\\t', quotechar='\"', escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews'] = data['comments']\n",
    "data = data.drop(columns=['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Make lowercase, remove punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews_clean'] = data['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove newlines, carriage returns, tabs\n",
    "data['reviews_clean'] = data['reviews_clean'].replace('\\n', ' ')\n",
    "data['reviews_clean'] = data['reviews_clean'].replace('\\t', ' ')\n",
    "data['reviews_clean'] = data['reviews_clean'].replace('\\r', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "exclude.add('\\n')\n",
    "exclude.add('\\r')\n",
    "exclude.add('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = int(len(data)/10)\n",
    "for i,r in data.iterrows():\n",
    "    if i > 10:\n",
    "        break\n",
    "    if i%checkpoint == 0:\n",
    "        print('cleaning', i)\n",
    "    s = r['reviews_clean']\n",
    "    new = ''\n",
    "    for ch in s:\n",
    "        if ch not in exclude:\n",
    "            new += ch\n",
    "        else:\n",
    "            new += ' '    \n",
    "    data.loc[i, 'reviews_clean'] = \" \".join(new.lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"a\", \"able\", \"about\", \"above\", \"abst\", \"accordance\", \"according\", \\\n",
    "\"accordingly\", \"across\", \"act\", \"actually\", \"added\", \"adj\", \\\n",
    "\"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"again\", \\\n",
    "\"against\", \"ah\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \\\n",
    "\"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"an\", \"and\", \\\n",
    "\"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \\\n",
    "\"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"apparently\", \\\n",
    "\"approximately\", \"are\", \"aren\", \"arent\", \"arise\", \"around\", \"as\", \\\n",
    "\"aside\", \"ask\", \"asking\", \"at\", \"auth\", \"available\", \"away\", \\\n",
    "\"awfully\", \"b\", \"back\", \"be\", \"became\", \"because\", \"become\", \\\n",
    "\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \\\n",
    "\"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \\\n",
    "\"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"biol\", \"both\", \\\n",
    "\"brief\", \"briefly\", \"but\", \"by\", \"c\", \"ca\", \"came\", \"can\", \"cannot\", \\\n",
    "\"cant\", \"cause\", \"causes\", \"certain\", \"certainly\", \"co\", \"com\", \\\n",
    "\"come\", \"comes\", \"contain\", \"containing\", \"contains\", \"could\", \\\n",
    "\"couldnt\", \"d\", \"date\", \"did\", \"didnt\", \"different\", \"do\", \"does\", \\\n",
    "\"doesnt\", \"doing\", \"done\", \"dont\", \"down\", \"downwards\", \"due\", \\\n",
    "\"during\", \"e\", \"each\", \"ed\", \"edu\", \"effect\", \"eg\", \"eight\", \\\n",
    "\"eighty\", \"either\", \"else\", \"elsewhere\", \"end\", \"ending\", \"enough\", \\\n",
    "\"especially\", \"et\", \"etc\", \"even\", \"ever\", \"every\", \\\n",
    "\"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"except\", \\\n",
    "\"f\", \"far\", \"few\", \"ff\", \"fifth\", \"first\", \"five\", \"fix\", \"followed\", \\\n",
    "\"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \\\n",
    "\"found\", \"four\", \"from\", \"further\", \"furthermore\", \"g\", \"gave\", \\\n",
    "\"get\", \"gets\", \"getting\", \"give\", \"given\", \"gives\", \"giving\", \"go\", \\\n",
    "\"goes\", \"gone\", \"got\", \"gotten\", \"h\", \"had\", \"happens\", \"hardly\", \\\n",
    "\"has\", \"hasnt\", \"have\", \"havent\", \"having\", \"he\", \"hed\", \"hence\", \\\n",
    "\"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \\\n",
    "\"hers\", \"herself\", \"hes\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \\\n",
    "\"hither\", \"home\", \"how\", \"howbeit\", \"however\", \"hundred\", \"i\", \"id\", \\\n",
    "\"ie\", \"if\", \"ill\", \"im\", \"immediate\", \"immediately\", \"importance\", \\\n",
    "\"important\", \"in\", \"inc\", \"indeed\", \"index\", \"information\", \\\n",
    "\"instead\", \"into\", \"invention\", \"inward\", \"is\", \"isnt\", \"it\", \"itd\", \\\n",
    "\"itll\", \"its\", \"itself\", \"ive\", \"j\", \"just\", \"k\", \"keep\", \"keeps\", \\\n",
    "\"kept\", \"kg\", \"km\", \"know\", \"known\", \"knows\", \"l\", \"largely\", \"last\", \\\n",
    "\"lately\", \"later\", \"latter\", \"latterly\", \"least\", \"less\", \"lest\", \\\n",
    "\"let\", \"lets\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"ll\", \\\n",
    "\"look\", \"looking\", \"looks\", \"ltd\", \"m\", \"made\", \"mainly\", \"make\", \\\n",
    "\"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \\\n",
    "\"meanwhile\", \"merely\", \"mg\", \"might\", \"million\", \"miss\", \"ml\", \\\n",
    "\"more\", \"moreover\", \"most\", \"mostly\", \"mr\", \"mrs\", \"much\", \"mug\", \\\n",
    "\"must\", \"my\", \"myself\", \"n\", \"na\", \"name\", \"namely\", \"nay\", \"nd\", \\\n",
    "\"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needs\", \\\n",
    "\"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"nine\", \"ninety\", \\\n",
    "\"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \\\n",
    "\"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"now\", \"nowhere\", \"o\", \\\n",
    "\"obtain\", \"obtained\", \"obviously\", \"of\", \"off\", \"often\", \"oh\", \"ok\", \\\n",
    "\"okay\", \"old\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \\\n",
    "\"onto\", \"or\", \"ord\", \"other\", \"others\", \"otherwise\", \"ought\", \"our\", \\\n",
    "\"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"owing\", \\\n",
    "\"own\", \"p\", \"page\", \"pages\", \"part\", \"particular\", \"particularly\", \\\n",
    "\"past\", \"per\", \"perhaps\", \"placed\", \"please\", \"plus\", \"poorly\", \\\n",
    "\"possible\", \"possibly\", \"potentially\", \"pp\", \"predominantly\", \\\n",
    "\"present\", \"previously\", \"primarily\", \"probably\", \"promptly\", \\\n",
    "\"proud\", \"provides\", \"put\", \"q\", \"que\", \"quickly\", \"quite\", \"qv\", \\\n",
    "\"r\", \"ran\", \"rather\", \"rd\", \"re\", \"readily\", \"really\", \"recent\", \\\n",
    "\"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \\\n",
    "\"related\", \"relatively\", \"research\", \"respectively\", \"resulted\", \\\n",
    "\"resulting\", \"results\", \"right\", \"run\", \"s\", \"said\", \"same\", \"saw\", \\\n",
    "\"say\", \"saying\", \"says\", \"sec\", \"section\", \"see\", \"seeing\", \"seem\", \\\n",
    "\"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sent\", \\\n",
    "\"seven\", \"several\", \"shall\", \"she\", \"shed\", \"shell\", \"shes\", \\\n",
    "\"should\", \"shouldnt\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \\\n",
    "\"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \\\n",
    "\"six\", \"slightly\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \\\n",
    "\"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \\\n",
    "\"somewhere\", \"soon\", \"sorry\", \"specifically\", \"specified\", \"specify\", \\\n",
    "\"specifying\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \\\n",
    "\"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"t\", \"take\", \"taken\", \"taking\", \"tell\", \"tends\", \"th\", \"than\", \\\n",
    "\"thank\", \"thanks\", \"thanx\", \"that\", \"thatll\", \"thats\", \"thatve\", \\\n",
    "\"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \\\n",
    "\"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \\\n",
    "\"therell\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \\\n",
    "\"thereve\", \"these\", \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \\\n",
    "\"think\", \"this\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \\\n",
    "\"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"til\", \"tip\", \\\n",
    "\"to\", \"together\", \"too\", \"took\", \"toward\", \"towards\", \"tried\", \\\n",
    "\"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"twice\", \"two\", \"u\", \"un\", \\\n",
    "\"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \\\n",
    "\"unto\", \"up\", \"upon\", \"ups\", \"us\", \"use\", \"used\", \"useful\", \\\n",
    "\"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"v\", \"value\", \\\n",
    "\"various\", \"ve\", \"very\", \"via\", \"viz\", \"vol\", \"vols\", \"vs\", \"w\", \\\n",
    "\"want\", \"wants\", \"was\", \"wasnt\", \"way\", \"we\", \"wed\", \"welcome\", \\\n",
    "\"well\", \"went\", \"were\", \"werent\", \"weve\", \"what\", \"whatever\", \\\n",
    "\"whatll\", \"whats\", \"when\", \"whence\", \"whenever\", \"where\", \\\n",
    "\"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\", \\\n",
    "\"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \\\n",
    "\"whod\", \"whoever\", \"whole\", \"wholl\", \"whom\", \"whomever\", \"whos\", \\\n",
    "\"whose\", \"why\", \"widely\", \"willing\", \"wish\", \"with\", \"within\", \\\n",
    "\"without\", \"wont\", \"words\", \"world\", \"would\", \"wouldnt\", \"www\", \"x\", \\\n",
    "\"y\", \"yes\", \"yet\", \"you\", \"youd\", \"youll\", \"your\", \"youre\", \"yours\", \\\n",
    "\"yourself\", \"yourselves\", \"youve\", \"z\", \"zero\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(s):\n",
    "    new = []\n",
    "    for word in s.split():\n",
    "        if word not in stop_words:\n",
    "            new.append(word)\n",
    "    return ' '.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes ~5 minutes\n",
    "data['reviews_stop'] = data['reviews_clean']\n",
    "checkpoint = int(len(data)/10)\n",
    "for i,r in data.iterrows():\n",
    "    if i > 10:\n",
    "        break\n",
    "    if (i%checkpoint)==0:\n",
    "        print('stop', i)\n",
    "    data.loc[i, 'reviews_stop'] = remove_stop(r['reviews_stop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews_stem'] = data['reviews_stop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(s):\n",
    "    new = []\n",
    "    for word in s.split():\n",
    "        new.append(snowball.stem(word))\n",
    "    return ' '.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = int(len(data)/10)\n",
    "for i,r in data.iterrows():\n",
    "    if i > 10:\n",
    "        break\n",
    "    if i%checkpoint == 0:\n",
    "        print('stem', i)\n",
    "    data.loc[i, 'reviews_stem'] = stem(r['reviews_stem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews_lemm'] = data['reviews_stop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(s):\n",
    "    new = []\n",
    "    for word in s.split():\n",
    "        new.append(lemmatizer.lemmatize(word))\n",
    "    return ' '.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = int(len(data)/10)\n",
    "for i,r in data.iterrows():\n",
    "    if i > 10:\n",
    "        break\n",
    "    if i%checkpoint == 0:\n",
    "        print('lemm', i)\n",
    "    data.loc[i, 'reviews_lemm'] = lemm(r['reviews_lemm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

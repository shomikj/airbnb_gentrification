{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_reviews.ipynb -- Preprocessing Script for Review Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../Data/reviews/reviews_raw/reviews_raw_london.csv'\n",
    "#data = pd.read_csv(file, delimiter='\\t', quotechar='\"', escapechar='\\\\')\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448240\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913</td>\n",
       "      <td>4847959</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>6405442</td>\n",
       "      <td>Vera</td>\n",
       "      <td>I'm very happy to have been Alina's guest! We'...</td>\n",
       "      <td>2013</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13913</td>\n",
       "      <td>8142329</td>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>9195551</td>\n",
       "      <td>Honi</td>\n",
       "      <td>I stayed with Alina in her flat in London for ...</td>\n",
       "      <td>2013</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13913</td>\n",
       "      <td>11876590</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>5194009</td>\n",
       "      <td>Alessandro</td>\n",
       "      <td>Alina was a perfect guest and her flat is abso...</td>\n",
       "      <td>2014</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13913</td>\n",
       "      <td>46669566</td>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>42970248</td>\n",
       "      <td>Oleh</td>\n",
       "      <td>Alina's flat is exceptional one.  \\r\\nI have t...</td>\n",
       "      <td>2015</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13913</td>\n",
       "      <td>64559033</td>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>45337884</td>\n",
       "      <td>Mo</td>\n",
       "      <td>The House is a piece of Art , there are beauti...</td>\n",
       "      <td>2016</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0       13913   4847959  2013-05-28      6405442          Vera   \n",
       "1       13913   8142329  2013-10-17      9195551          Honi   \n",
       "2       13913  11876590  2014-04-17      5194009    Alessandro   \n",
       "3       13913  46669566  2015-09-12     42970248          Oleh   \n",
       "4       13913  64559033  2016-03-05     45337884            Mo   \n",
       "\n",
       "                                            comments  year language  \n",
       "0  I'm very happy to have been Alina's guest! We'...  2013       en  \n",
       "1  I stayed with Alina in her flat in London for ...  2013       en  \n",
       "2  Alina was a perfect guest and her flat is abso...  2014       en  \n",
       "3  Alina's flat is exceptional one.  \\r\\nI have t...  2015       en  \n",
       "4  The House is a piece of Art , there are beauti...  2016       en  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 -- Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews_clean'] = data['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove newlines, carriage returns, tabs\n",
    "data['reviews_clean'] = data['reviews_clean'].replace('\\n', ' ')\n",
    "data['reviews_clean'] = data['reviews_clean'].replace('\\t', ' ')\n",
    "data['reviews_clean'] = data['reviews_clean'].replace('\\r', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{';', '>', '=', '\\n', '\\t', '\\r', '+', ',', ']', ')', ':', '(', \"'\", '#', '/', '\\\\', '!', '-', '%', '`', '|', '\"', '&', '_', '@', '}', '[', '{', '<', '^', '.', '*', '~', '?', '$'}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "exclude.add('\\n')\n",
    "exclude.add('\\r')\n",
    "exclude.add('\\t')\n",
    "print(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448240it [01:50, 4064.74it/s]\n"
     ]
    }
   ],
   "source": [
    "clean = [] \n",
    "for i,r in tqdm(data.iterrows()):\n",
    "    s = r['reviews_clean']\n",
    "    new = ''\n",
    "    if (pd.notna(s)):\n",
    "        for ch in s:\n",
    "            if ch not in exclude:\n",
    "                new += ch\n",
    "            else:\n",
    "                new += ' '    \n",
    "        clean.append(\" \".join(new.lower().split()))\n",
    "    else:\n",
    "        clean.append(np.nan)\n",
    "data['reviews_clean'] = clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 -- Remove StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"a\", \"able\", \"about\", \"above\", \"abst\", \"accordance\", \"according\", \\\n",
    "\"accordingly\", \"across\", \"act\", \"actually\", \"added\", \"adj\", \\\n",
    "\"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"again\", \\\n",
    "\"against\", \"ah\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \\\n",
    "\"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"an\", \"and\", \\\n",
    "\"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \\\n",
    "\"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"apparently\", \\\n",
    "\"approximately\", \"are\", \"aren\", \"arent\", \"arise\", \"around\", \"as\", \\\n",
    "\"aside\", \"ask\", \"asking\", \"at\", \"auth\", \"available\", \"away\", \\\n",
    "\"awfully\", \"b\", \"back\", \"be\", \"became\", \"because\", \"become\", \\\n",
    "\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \\\n",
    "\"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \\\n",
    "\"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"biol\", \"both\", \\\n",
    "\"brief\", \"briefly\", \"but\", \"by\", \"c\", \"ca\", \"came\", \"can\", \"cannot\", \\\n",
    "\"cant\", \"cause\", \"causes\", \"certain\", \"certainly\", \"co\", \"com\", \\\n",
    "\"come\", \"comes\", \"contain\", \"containing\", \"contains\", \"could\", \\\n",
    "\"couldnt\", \"d\", \"date\", \"did\", \"didnt\", \"different\", \"do\", \"does\", \\\n",
    "\"doesnt\", \"doing\", \"done\", \"dont\", \"down\", \"downwards\", \"due\", \\\n",
    "\"during\", \"e\", \"each\", \"ed\", \"edu\", \"effect\", \"eg\", \"eight\", \\\n",
    "\"eighty\", \"either\", \"else\", \"elsewhere\", \"end\", \"ending\", \"enough\", \\\n",
    "\"especially\", \"et\", \"etc\", \"even\", \"ever\", \"every\", \\\n",
    "\"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"except\", \\\n",
    "\"f\", \"far\", \"few\", \"ff\", \"fifth\", \"first\", \"five\", \"fix\", \"followed\", \\\n",
    "\"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \\\n",
    "\"found\", \"four\", \"from\", \"further\", \"furthermore\", \"g\", \"gave\", \\\n",
    "\"get\", \"gets\", \"getting\", \"give\", \"given\", \"gives\", \"giving\", \"go\", \\\n",
    "\"goes\", \"gone\", \"got\", \"gotten\", \"h\", \"had\", \"happens\", \"hardly\", \\\n",
    "\"has\", \"hasnt\", \"have\", \"havent\", \"having\", \"he\", \"hed\", \"hence\", \\\n",
    "\"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \\\n",
    "\"hers\", \"herself\", \"hes\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \\\n",
    "\"hither\", \"home\", \"how\", \"howbeit\", \"however\", \"hundred\", \"i\", \"id\", \\\n",
    "\"ie\", \"if\", \"ill\", \"im\", \"immediate\", \"immediately\", \"importance\", \\\n",
    "\"important\", \"in\", \"inc\", \"indeed\", \"index\", \"information\", \\\n",
    "\"instead\", \"into\", \"invention\", \"inward\", \"is\", \"isnt\", \"it\", \"itd\", \\\n",
    "\"itll\", \"its\", \"itself\", \"ive\", \"j\", \"just\", \"k\", \"keep\", \"keeps\", \\\n",
    "\"kept\", \"kg\", \"km\", \"know\", \"known\", \"knows\", \"l\", \"largely\", \"last\", \\\n",
    "\"lately\", \"later\", \"latter\", \"latterly\", \"least\", \"less\", \"lest\", \\\n",
    "\"let\", \"lets\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"ll\", \\\n",
    "\"look\", \"looking\", \"looks\", \"ltd\", \"m\", \"made\", \"mainly\", \"make\", \\\n",
    "\"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \\\n",
    "\"meanwhile\", \"merely\", \"mg\", \"might\", \"million\", \"miss\", \"ml\", \\\n",
    "\"more\", \"moreover\", \"most\", \"mostly\", \"mr\", \"mrs\", \"much\", \"mug\", \\\n",
    "\"must\", \"my\", \"myself\", \"n\", \"na\", \"name\", \"namely\", \"nay\", \"nd\", \\\n",
    "\"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needs\", \\\n",
    "\"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"nine\", \"ninety\", \\\n",
    "\"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \\\n",
    "\"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"now\", \"nowhere\", \"o\", \\\n",
    "\"obtain\", \"obtained\", \"obviously\", \"of\", \"off\", \"often\", \"oh\", \"ok\", \\\n",
    "\"okay\", \"old\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \\\n",
    "\"onto\", \"or\", \"ord\", \"other\", \"others\", \"otherwise\", \"ought\", \"our\", \\\n",
    "\"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"owing\", \\\n",
    "\"own\", \"p\", \"page\", \"pages\", \"part\", \"particular\", \"particularly\", \\\n",
    "\"past\", \"per\", \"perhaps\", \"placed\", \"please\", \"plus\", \"poorly\", \\\n",
    "\"possible\", \"possibly\", \"potentially\", \"pp\", \"predominantly\", \\\n",
    "\"present\", \"previously\", \"primarily\", \"probably\", \"promptly\", \\\n",
    "\"proud\", \"provides\", \"put\", \"q\", \"que\", \"quickly\", \"quite\", \"qv\", \\\n",
    "\"r\", \"ran\", \"rather\", \"rd\", \"re\", \"readily\", \"really\", \"recent\", \\\n",
    "\"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \\\n",
    "\"related\", \"relatively\", \"research\", \"respectively\", \"resulted\", \\\n",
    "\"resulting\", \"results\", \"right\", \"run\", \"s\", \"said\", \"same\", \"saw\", \\\n",
    "\"say\", \"saying\", \"says\", \"sec\", \"section\", \"see\", \"seeing\", \"seem\", \\\n",
    "\"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sent\", \\\n",
    "\"seven\", \"several\", \"shall\", \"she\", \"shed\", \"shell\", \"shes\", \\\n",
    "\"should\", \"shouldnt\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \\\n",
    "\"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \\\n",
    "\"six\", \"slightly\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \\\n",
    "\"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \\\n",
    "\"somewhere\", \"soon\", \"sorry\", \"specifically\", \"specified\", \"specify\", \\\n",
    "\"specifying\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \\\n",
    "\"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"t\", \"take\", \"taken\", \"taking\", \"tell\", \"tends\", \"th\", \"than\", \\\n",
    "\"thank\", \"thanks\", \"thanx\", \"that\", \"thatll\", \"thats\", \"thatve\", \\\n",
    "\"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \\\n",
    "\"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \\\n",
    "\"therell\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \\\n",
    "\"thereve\", \"these\", \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \\\n",
    "\"think\", \"this\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \\\n",
    "\"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"til\", \"tip\", \\\n",
    "\"to\", \"together\", \"too\", \"took\", \"toward\", \"towards\", \"tried\", \\\n",
    "\"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"twice\", \"two\", \"u\", \"un\", \\\n",
    "\"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \\\n",
    "\"unto\", \"up\", \"upon\", \"ups\", \"us\", \"use\", \"used\", \"useful\", \\\n",
    "\"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"v\", \"value\", \\\n",
    "\"various\", \"ve\", \"very\", \"via\", \"viz\", \"vol\", \"vols\", \"vs\", \"w\", \\\n",
    "\"want\", \"wants\", \"was\", \"wasnt\", \"way\", \"we\", \"wed\", \"welcome\", \\\n",
    "\"well\", \"went\", \"were\", \"werent\", \"weve\", \"what\", \"whatever\", \\\n",
    "\"whatll\", \"whats\", \"when\", \"whence\", \"whenever\", \"where\", \\\n",
    "\"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\", \\\n",
    "\"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \\\n",
    "\"whod\", \"whoever\", \"whole\", \"wholl\", \"whom\", \"whomever\", \"whos\", \\\n",
    "\"whose\", \"why\", \"widely\", \"willing\", \"wish\", \"with\", \"within\", \\\n",
    "\"without\", \"wont\", \"words\", \"world\", \"would\", \"wouldnt\", \"www\", \"x\", \\\n",
    "\"y\", \"yes\", \"yet\", \"you\", \"youd\", \"youll\", \"your\", \"youre\", \"yours\", \\\n",
    "\"yourself\", \"yourselves\", \"youve\", \"z\", \"zero\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(s):\n",
    "    new = []\n",
    "    for word in s.split():\n",
    "        if word not in stop_words:\n",
    "            new.append(word)\n",
    "    return ' '.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448240it [04:15, 1752.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# takes ~5 minutes\n",
    "clean = []\n",
    "for i,r in tqdm(data.iterrows()):\n",
    "    s = r['reviews_clean']\n",
    "    if pd.notna(s):\n",
    "        clean.append(remove_stop(s))\n",
    "    else:\n",
    "        clean.append(np.nan)\n",
    "data['reviews_clean'] = clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 -- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(s):\n",
    "    new = []\n",
    "    for word in s.split():\n",
    "        new.append(snowball.stem(word))\n",
    "    return ' '.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448240it [05:02, 1483.73it/s]\n"
     ]
    }
   ],
   "source": [
    "clean = []\n",
    "for i,r in tqdm(data.iterrows()):\n",
    "    s = r['reviews_clean']\n",
    "    if pd.notna(s):\n",
    "        clean.append(stem(s))\n",
    "    else:\n",
    "        clean.append(np.nan)\n",
    "data['reviews_clean'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../Data/reviews/reviews_clean/reviews_clean_london.csv'\n",
    "data.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>reviews_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913</td>\n",
       "      <td>4847959</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>6405442</td>\n",
       "      <td>Vera</td>\n",
       "      <td>2013</td>\n",
       "      <td>en</td>\n",
       "      <td>happi alina guest great time london enjoy stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13913</td>\n",
       "      <td>8142329</td>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>9195551</td>\n",
       "      <td>Honi</td>\n",
       "      <td>2013</td>\n",
       "      <td>en</td>\n",
       "      <td>stay alina flat london week wonder warm feel a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13913</td>\n",
       "      <td>11876590</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>5194009</td>\n",
       "      <td>Alessandro</td>\n",
       "      <td>2014</td>\n",
       "      <td>en</td>\n",
       "      <td>alina perfect guest flat absolut wonder high r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13913</td>\n",
       "      <td>46669566</td>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>42970248</td>\n",
       "      <td>Oleh</td>\n",
       "      <td>2015</td>\n",
       "      <td>en</td>\n",
       "      <td>alina flat except atmospher place flat plenti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13913</td>\n",
       "      <td>64559033</td>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>45337884</td>\n",
       "      <td>Mo</td>\n",
       "      <td>2016</td>\n",
       "      <td>en</td>\n",
       "      <td>hous piec art beauti portrait close tube stati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  year language  \\\n",
       "0       13913   4847959  2013-05-28      6405442          Vera  2013       en   \n",
       "1       13913   8142329  2013-10-17      9195551          Honi  2013       en   \n",
       "2       13913  11876590  2014-04-17      5194009    Alessandro  2014       en   \n",
       "3       13913  46669566  2015-09-12     42970248          Oleh  2015       en   \n",
       "4       13913  64559033  2016-03-05     45337884            Mo  2016       en   \n",
       "\n",
       "                                       reviews_clean  \n",
       "0  happi alina guest great time london enjoy stay...  \n",
       "1  stay alina flat london week wonder warm feel a...  \n",
       "2  alina perfect guest flat absolut wonder high r...  \n",
       "3  alina flat except atmospher place flat plenti ...  \n",
       "4  hous piec art beauti portrait close tube stati...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alina perfect guest flat absolut wonder high recommend'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reviews_clean'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

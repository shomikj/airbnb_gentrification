{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstructured_features.py -- Calculate Unstructured Features (LDA, D2V, LocationWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'london'\n",
    "reviews_file = '../../../Data/reviews/reviews_clean/reviews_clean_'+city+'.csv'\n",
    "data = pd.read_csv(reviews_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>reviews_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913</td>\n",
       "      <td>4847959</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>6405442</td>\n",
       "      <td>Vera</td>\n",
       "      <td>2013</td>\n",
       "      <td>en</td>\n",
       "      <td>happi alina guest great time london enjoy stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13913</td>\n",
       "      <td>8142329</td>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>9195551</td>\n",
       "      <td>Honi</td>\n",
       "      <td>2013</td>\n",
       "      <td>en</td>\n",
       "      <td>stay alina flat london week wonder warm feel a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13913</td>\n",
       "      <td>11876590</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>5194009</td>\n",
       "      <td>Alessandro</td>\n",
       "      <td>2014</td>\n",
       "      <td>en</td>\n",
       "      <td>alina perfect guest flat absolut wonder high r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13913</td>\n",
       "      <td>46669566</td>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>42970248</td>\n",
       "      <td>Oleh</td>\n",
       "      <td>2015</td>\n",
       "      <td>en</td>\n",
       "      <td>alina flat except atmospher place flat plenti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13913</td>\n",
       "      <td>64559033</td>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>45337884</td>\n",
       "      <td>Mo</td>\n",
       "      <td>2016</td>\n",
       "      <td>en</td>\n",
       "      <td>hous piec art beauti portrait close tube stati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  year language  \\\n",
       "0       13913   4847959  2013-05-28      6405442          Vera  2013       en   \n",
       "1       13913   8142329  2013-10-17      9195551          Honi  2013       en   \n",
       "2       13913  11876590  2014-04-17      5194009    Alessandro  2014       en   \n",
       "3       13913  46669566  2015-09-12     42970248          Oleh  2015       en   \n",
       "4       13913  64559033  2016-03-05     45337884            Mo  2016       en   \n",
       "\n",
       "                                       reviews_clean  \n",
       "0  happi alina guest great time london enjoy stay...  \n",
       "1  stay alina flat london week wonder warm feel a...  \n",
       "2  alina perfect guest flat absolut wonder high r...  \n",
       "3  alina flat except atmospher place flat plenti ...  \n",
       "4  hous piec art beauti portrait close tube stati...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = '../../../Data/reviews/reviews_data/reviews_data_'+city+'.csv'\n",
    "output = pd.read_csv(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sent_comp</th>\n",
       "      <th>sent_pos</th>\n",
       "      <th>sent_neg</th>\n",
       "      <th>sent_neu</th>\n",
       "      <th>lda1</th>\n",
       "      <th>lda2</th>\n",
       "      <th>lda3</th>\n",
       "      <th>lda4</th>\n",
       "      <th>lda5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4847959</td>\n",
       "      <td>13913</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.280112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069759</td>\n",
       "      <td>0.428841</td>\n",
       "      <td>0.218180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8142329</td>\n",
       "      <td>13913</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.883986</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11876590</td>\n",
       "      <td>13913</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.022453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46669566</td>\n",
       "      <td>13913</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616192</td>\n",
       "      <td>0.243901</td>\n",
       "      <td>0.127574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64559033</td>\n",
       "      <td>13913</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.308462</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.506747</td>\n",
       "      <td>0.011315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  listing_id  year  month  day  sent_comp  sent_pos  sent_neg  \\\n",
       "0   4847959       13913  2013      5   28     0.9954     0.302       0.0   \n",
       "1   8142329       13913  2013     10   17     0.9623     0.272       0.0   \n",
       "2  11876590       13913  2014      4   17     0.8764     0.501       0.0   \n",
       "3  46669566       13913  2015      9   12     0.9826     0.320       0.0   \n",
       "4  64559033       13913  2016      3    5     0.9127     0.250       0.0   \n",
       "\n",
       "   sent_neu      lda1      lda2      lda3      lda4      lda5  \n",
       "0     0.698  0.280112  0.000000  0.069759  0.428841  0.218180  \n",
       "1     0.728  0.000000  0.000000  0.086864  0.883986  0.000000  \n",
       "2     0.499  0.022306  0.022497  0.022692  0.910053  0.022453  \n",
       "3     0.680  0.000000  0.000000  0.616192  0.243901  0.127574  \n",
       "4     0.750  0.308462  0.011283  0.162193  0.506747  0.011315  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447979 447979\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[data['reviews_clean'].notna()]\n",
    "data = data[data['reviews_clean'].notna()]\n",
    "\n",
    "output = output.reset_index(drop=True)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447979 447979\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(reviews_file, index=False)\n",
    "output.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 447979/447979 [00:03<00:00, 118219.50it/s]\n"
     ]
    }
   ],
   "source": [
    "reviews = data['reviews_clean']\n",
    "bow = []\n",
    "for r in tqdm(reviews):\n",
    "    bow.append(r.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(bow)\n",
    "\n",
    "# remove words appearing in less than 100 reviews\n",
    "dictionary.filter_extremes(no_below=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting LDA\n",
      "lda done\n"
     ]
    }
   ],
   "source": [
    "# Run LDA\n",
    "print('starting LDA')\n",
    "\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, num_topics = num_topics, id2word = dictionary, passes = 5, workers=2)\n",
    "\n",
    "print('lda done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.057*\"station\" + 0.053*\"walk\" + 0.039*\"minut\" + 0.029*\"london\" + 0.026*\"tube\" + 0.025*\"bus\" + 0.021*\"place\" + 0.017*\"close\" + 0.017*\"min\" + 0.015*\"5\" + 0.015*\"10\" + 0.015*\"train\" + 0.015*\"hous\" + 0.014*\"stay\" + 0.012*\"underground\" + 0.012*\"nice\" + 0.010*\"locat\" + 0.010*\"2\" + 0.009*\"clean\" + 0.008*\"citi\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.058*\"great\" + 0.048*\"locat\" + 0.047*\"nice\" + 0.044*\"good\" + 0.044*\"clean\" + 0.038*\"place\" + 0.033*\"stay\" + 0.027*\"room\" + 0.025*\"apart\" + 0.023*\"host\" + 0.020*\"easi\" + 0.018*\"flat\" + 0.017*\"communic\" + 0.017*\"close\" + 0.015*\"check\" + 0.015*\"comfort\" + 0.015*\"recommend\" + 0.012*\"help\" + 0.012*\"london\" + 0.011*\"transport\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.029*\"great\" + 0.027*\"flat\" + 0.023*\"locat\" + 0.021*\"restaur\" + 0.021*\"love\" + 0.020*\"stay\" + 0.019*\"london\" + 0.018*\"apart\" + 0.015*\"shop\" + 0.014*\"close\" + 0.014*\"area\" + 0.013*\"walk\" + 0.012*\"park\" + 0.011*\"perfect\" + 0.010*\"recommend\" + 0.010*\"street\" + 0.010*\"quiet\" + 0.010*\"place\" + 0.009*\"high\" + 0.009*\"comfort\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.062*\"stay\" + 0.038*\"place\" + 0.036*\"great\" + 0.036*\"host\" + 0.032*\"love\" + 0.030*\"recommend\" + 0.021*\"london\" + 0.019*\"clean\" + 0.018*\"help\" + 0.018*\"locat\" + 0.018*\"hous\" + 0.017*\"friend\" + 0.016*\"room\" + 0.015*\"definit\" + 0.015*\"comfort\" + 0.015*\"high\" + 0.015*\"perfect\" + 0.013*\"time\" + 0.013*\"will\" + 0.011*\"welcom\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.020*\"day\" + 0.019*\"arriv\" + 0.018*\"host\" + 0.016*\"room\" + 0.012*\"bed\" + 0.011*\"bathroom\" + 0.010*\"night\" + 0.010*\"kitchen\" + 0.009*\"check\" + 0.009*\"reserv\" + 0.009*\"cancel\" + 0.009*\"post\" + 0.008*\"shower\" + 0.008*\"autom\" + 0.008*\"work\" + 0.007*\"apart\" + 0.007*\"time\" + 0.007*\"bit\" + 0.006*\"issu\" + 0.006*\"stay\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(num_topics=-1, num_words=20):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 1613.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting scores per review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "417637it [03:20, 2489.88it/s]"
     ]
    }
   ],
   "source": [
    "print('getting scores per review')\n",
    "all_scores = []\n",
    "\n",
    "for i, review in tqdm(enumerate(bow_corpus)):\n",
    "    scores = list(np.zeros(num_topics))\n",
    "    for i in lda_model[review]:\n",
    "        scores[i[0]] = i[1]\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_cols = ['lda1', 'lda2', 'lda3', 'lda4', 'lda5']\n",
    "for i in lda_cols:\n",
    "    output[i] = np.nan\n",
    "\n",
    "output.loc[:, lda_cols] = all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 447979/447979 [00:02<00:00, 182107.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set up reviews to map\n",
    "\n",
    "process = data['reviews_clean']\n",
    "\n",
    "reviews = []\n",
    "for r in tqdm(process):\n",
    "    reviews.append(r.split())\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up multithreading\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "#assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "ending training\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "s=25\n",
    "\n",
    "print('starting training')\n",
    "model = Doc2Vec(documents, vector_size=s, window=3, min_count=100, workers=cores, epochs=10)\n",
    "print('ending training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 447979/447979 [00:02<00:00, 155089.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Record Mappings\n",
    "\n",
    "vectors = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    vectors.append(list(model.docvecs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtv_cols = []\n",
    "for i in range(0, s):\n",
    "    dtv_cols.append('dtv_'+str(i+1))\n",
    "\n",
    "for i in dtv_cols:\n",
    "    output[i] = np.nan\n",
    "    \n",
    "output.loc[:, dtv_cols] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sent_comp</th>\n",
       "      <th>sent_pos</th>\n",
       "      <th>sent_neg</th>\n",
       "      <th>sent_neu</th>\n",
       "      <th>lda1</th>\n",
       "      <th>...</th>\n",
       "      <th>dtv_16</th>\n",
       "      <th>dtv_17</th>\n",
       "      <th>dtv_18</th>\n",
       "      <th>dtv_19</th>\n",
       "      <th>dtv_20</th>\n",
       "      <th>dtv_21</th>\n",
       "      <th>dtv_22</th>\n",
       "      <th>dtv_23</th>\n",
       "      <th>dtv_24</th>\n",
       "      <th>dtv_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4847959</td>\n",
       "      <td>13913</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.280112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111499</td>\n",
       "      <td>-0.094669</td>\n",
       "      <td>0.220386</td>\n",
       "      <td>0.036887</td>\n",
       "      <td>-0.018792</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>-0.015888</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>-0.203862</td>\n",
       "      <td>0.132382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8142329</td>\n",
       "      <td>13913</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064924</td>\n",
       "      <td>-0.051245</td>\n",
       "      <td>0.132313</td>\n",
       "      <td>0.067979</td>\n",
       "      <td>-0.129214</td>\n",
       "      <td>-0.045868</td>\n",
       "      <td>-0.067976</td>\n",
       "      <td>0.026742</td>\n",
       "      <td>-0.046301</td>\n",
       "      <td>0.108684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11876590</td>\n",
       "      <td>13913</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059626</td>\n",
       "      <td>-0.186169</td>\n",
       "      <td>0.043521</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>-0.130722</td>\n",
       "      <td>-0.013105</td>\n",
       "      <td>0.074104</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.016121</td>\n",
       "      <td>-0.009348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46669566</td>\n",
       "      <td>13913</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199562</td>\n",
       "      <td>-0.305227</td>\n",
       "      <td>0.053984</td>\n",
       "      <td>0.061121</td>\n",
       "      <td>0.051538</td>\n",
       "      <td>0.175705</td>\n",
       "      <td>0.125290</td>\n",
       "      <td>-0.157890</td>\n",
       "      <td>-0.132678</td>\n",
       "      <td>-0.249155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64559033</td>\n",
       "      <td>13913</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.308462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065330</td>\n",
       "      <td>-0.137538</td>\n",
       "      <td>-0.037017</td>\n",
       "      <td>-0.028817</td>\n",
       "      <td>-0.065899</td>\n",
       "      <td>0.225425</td>\n",
       "      <td>0.132233</td>\n",
       "      <td>0.042780</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>-0.029153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  listing_id  year  month  day  sent_comp  sent_pos  sent_neg  \\\n",
       "0   4847959       13913  2013      5   28     0.9954     0.302       0.0   \n",
       "1   8142329       13913  2013     10   17     0.9623     0.272       0.0   \n",
       "2  11876590       13913  2014      4   17     0.8764     0.501       0.0   \n",
       "3  46669566       13913  2015      9   12     0.9826     0.320       0.0   \n",
       "4  64559033       13913  2016      3    5     0.9127     0.250       0.0   \n",
       "\n",
       "   sent_neu      lda1  ...    dtv_16    dtv_17    dtv_18    dtv_19    dtv_20  \\\n",
       "0     0.698  0.280112  ...  0.111499 -0.094669  0.220386  0.036887 -0.018792   \n",
       "1     0.728  0.000000  ...  0.064924 -0.051245  0.132313  0.067979 -0.129214   \n",
       "2     0.499  0.022306  ...  0.059626 -0.186169  0.043521  0.008656 -0.130722   \n",
       "3     0.680  0.000000  ... -0.199562 -0.305227  0.053984  0.061121  0.051538   \n",
       "4     0.750  0.308462  ...  0.065330 -0.137538 -0.037017 -0.028817 -0.065899   \n",
       "\n",
       "     dtv_21    dtv_22    dtv_23    dtv_24    dtv_25  \n",
       "0  0.181200 -0.015888  0.017920 -0.203862  0.132382  \n",
       "1 -0.045868 -0.067976  0.026742 -0.046301  0.108684  \n",
       "2 -0.013105  0.074104  0.000356  0.016121 -0.009348  \n",
       "3  0.175705  0.125290 -0.157890 -0.132678 -0.249155  \n",
       "4  0.225425  0.132233  0.042780  0.006165 -0.029153  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_words = [\n",
    "'Abuse', \n",
    "'Accomplice', \n",
    "'Accuse',\n",
    "'Activists',\n",
    "'Against',\n",
    "'Aggravated',\n",
    "'assault', \n",
    "'Alarm',\n",
    "'Alert', \n",
    "'Allegation', \n",
    "'Ammunition', \n",
    "'APB', \n",
    "'Armed', \n",
    "'Arraignment', \n",
    "'Arrest',\n",
    "'Arsenal', \n",
    "'Arson',\n",
    "'Assailant',\n",
    "'Assault', \n",
    "'Attack', \n",
    "'Autopsy',\n",
    "'Bail', \n",
    "'Battery', \n",
    "'Beat', \n",
    "'Blackmail', \n",
    "'Blood',\n",
    "'Bomb', \n",
    "'Brawl', \n",
    "'Breach', \n",
    "'Break',\n",
    "'Bribe', \n",
    "'Brutal', \n",
    "'Bully',\n",
    "'Burglary',\n",
    "'Bystander',\n",
    "'Capture', \n",
    "'Caution', \n",
    "'Coercion',\n",
    "'Collusion', \n",
    "'Combat',\n",
    "'Complain',\n",
    "'Conspiracy', \n",
    "'Convict', \n",
    "'Cops', \n",
    "'Coroner', \n",
    "'Corrupt',\n",
    "'Counterfeit', \n",
    "'CIA',\n",
    "'Crime', \n",
    "'Criminal',\n",
    "'Criminology',\n",
    "'Cuffs',\n",
    "'Custody',\n",
    "'Damage',\n",
    "'Danger',\n",
    "'Dangerous', \n",
    "'Dead', \n",
    "'Death',\n",
    "'Defense',\n",
    "'Deputy',\n",
    "'Detain', \n",
    "'Detective', \n",
    "'Disorderly', \n",
    "'Dispatch', \n",
    "'DNA', \n",
    "'Drugs', \n",
    "'Emergency', \n",
    "'Evasive', \n",
    "'Eviction', \n",
    "'Evil',\n",
    "'Explosives', \n",
    "'Extradition', \n",
    "'Fatality', \n",
    "'FBI',\n",
    "'Felony',\n",
    "'Fight',\n",
    "'Fingerprint', \n",
    "'Firebombing',\n",
    "'Flee', \n",
    "'Forensics', \n",
    "'Forgery', \n",
    "'Fraud',\n",
    "'Gory',\n",
    "'Guard',\n",
    "'Gun',\n",
    "'Handcuffs',\n",
    "'Harassment',\n",
    "'Homeless',\n",
    "'Harm', \n",
    "'Heinous',\n",
    "'Hijack',\n",
    "'Holster', \n",
    "'Homicide', \n",
    "'Hostage',\n",
    "'Illegal', \n",
    "'Immoral', \n",
    "'Immunity', \n",
    "'Impeach', \n",
    "'Imprison',\n",
    "'Incarceration',\n",
    "'Incriminating', \n",
    "'Indictment', \n",
    "'Injury', \n",
    "'Inmate',\n",
    "'Intruder',\n",
    "'Invasive',\n",
    "'Investigation',\n",
    "'Jail',\n",
    "'Juvenile',\n",
    "'Kidnapping',\n",
    "'Kill',\n",
    "'Killer', \n",
    "'Larceny',\n",
    "'Legal',\n",
    "'Lynch',\n",
    "'Mace',\n",
    "'Malice',\n",
    "'Malpractice',\n",
    "'Manacled',\n",
    "'Manslaughter',\n",
    "'Misdemeanor',\n",
    "'Murder',\n",
    "'Murderer',\n",
    "'911', \n",
    "'Offender',\n",
    "'Offense',\n",
    "'Officer',\n",
    "'Patrol',\n",
    "'Perjury',\n",
    "'Perpetrator',\n",
    "'Plea',\n",
    "'Police', \n",
    "'Prison',\n",
    "'Probation',\n",
    "'Prosecute',\n",
    "'Prosecutor',\n",
    "'Prostitution',\n",
    "'Radar', \n",
    "'Rape',\n",
    "'Riot',\n",
    "'Robbery',\n",
    "'Rogue',\n",
    "'Safe',\n",
    "'Sanction',\n",
    "'Sergeant',\n",
    "'Shackles',\n",
    "'Sheriff', \n",
    "'Shooting',\n",
    "'Smuggling',\n",
    "'Spying',\n",
    "'Subpoena',\n",
    "'Summons',\n",
    "'Surveillance',\n",
    "'Suspect',\n",
    "'Suspicious',\n",
    "'Terrorism',\n",
    "'Theft',\n",
    "'Threatening',\n",
    "'Torture',\n",
    "'Trauma',\n",
    "'Unauthorized',\n",
    "'Unlawful',\n",
    "'Vagrancy',\n",
    "'Vandalism',\n",
    "'Victim',\n",
    "'Violation',\n",
    "'Violence',\n",
    "'Warning',\n",
    "'Weapon',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = {}\n",
    "words_dict['crime_words'] = crime_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv('airbnb_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cat_lev1</th>\n",
       "      <th>cat_lev2</th>\n",
       "      <th>cat_lev3</th>\n",
       "      <th>ndf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>information</td>\n",
       "      <td>business</td>\n",
       "      <td>professional_conduct_host</td>\n",
       "      <td>advice</td>\n",
       "      <td>0.008904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recommendations</td>\n",
       "      <td>business</td>\n",
       "      <td>professional_conduct_host</td>\n",
       "      <td>advice</td>\n",
       "      <td>0.008375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tips</td>\n",
       "      <td>business</td>\n",
       "      <td>professional_conduct_host</td>\n",
       "      <td>advice</td>\n",
       "      <td>0.008399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>advice</td>\n",
       "      <td>business</td>\n",
       "      <td>professional_conduct_host</td>\n",
       "      <td>advice</td>\n",
       "      <td>0.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suggestions</td>\n",
       "      <td>business</td>\n",
       "      <td>professional_conduct_host</td>\n",
       "      <td>advice</td>\n",
       "      <td>0.007580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  cat_lev1                   cat_lev2 cat_lev3       ndf\n",
       "0      information  business  professional_conduct_host   advice  0.008904\n",
       "1  recommendations  business  professional_conduct_host   advice  0.008375\n",
       "2             tips  business  professional_conduct_host   advice  0.008399\n",
       "3           advice  business  professional_conduct_host   advice  0.007568\n",
       "4      suggestions  business  professional_conduct_host   advice  0.007580"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict['location_words'] = list(words[words['cat_lev2']=='location']['word'].values)\n",
    "words_dict['business_words'] = list(words[words['cat_lev1']=='business']['word'].values)\n",
    "words_dict['social_words'] = list(words[words['cat_lev1']=='social']['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(w):\n",
    "    return snowball.stem(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat,words in words_dict.items():\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        new_words.append(stem(w.lower()))\n",
    "    words_dict[cat]=new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "447979it [02:37, 2845.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add Words Features\n",
    "\n",
    "review_len = []\n",
    "feature = {}\n",
    "for cat in words_dict.keys():\n",
    "    feature[cat] = []\n",
    "    \n",
    "for i,r in tqdm(data.iterrows()):\n",
    "    bow = r['reviews_clean'].lower().split()\n",
    "    review_len.append(len(bow))\n",
    "    \n",
    "    counts = Counter(bow)\n",
    "\n",
    "    for cat,words in words_dict.items():\n",
    "        total = 0\n",
    "        for w in words:\n",
    "            total += counts[w]\n",
    "        feature[cat].append(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['crime_words', 'location_words', 'business_words', 'social_words'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['review_len'] = review_len\n",
    "for cat,counts in feature.items():\n",
    "    output[cat] = counts\n",
    "    output[cat+'_perc'] = output[cat]/output['review_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sent_comp</th>\n",
       "      <th>sent_pos</th>\n",
       "      <th>sent_neg</th>\n",
       "      <th>sent_neu</th>\n",
       "      <th>lda1</th>\n",
       "      <th>...</th>\n",
       "      <th>dtv_25</th>\n",
       "      <th>review_len</th>\n",
       "      <th>crime_words</th>\n",
       "      <th>crime_words_perc</th>\n",
       "      <th>location_words</th>\n",
       "      <th>location_words_perc</th>\n",
       "      <th>business_words</th>\n",
       "      <th>business_words_perc</th>\n",
       "      <th>social_words</th>\n",
       "      <th>social_words_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4847959</td>\n",
       "      <td>13913</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.280112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132382</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>31</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8142329</td>\n",
       "      <td>13913</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108684</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11876590</td>\n",
       "      <td>13913</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009348</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46669566</td>\n",
       "      <td>13913</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249155</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>13</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64559033</td>\n",
       "      <td>13913</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.308462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029153</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>9</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>4</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  listing_id  year  month  day  sent_comp  sent_pos  sent_neg  \\\n",
       "0   4847959       13913  2013      5   28     0.9954     0.302       0.0   \n",
       "1   8142329       13913  2013     10   17     0.9623     0.272       0.0   \n",
       "2  11876590       13913  2014      4   17     0.8764     0.501       0.0   \n",
       "3  46669566       13913  2015      9   12     0.9826     0.320       0.0   \n",
       "4  64559033       13913  2016      3    5     0.9127     0.250       0.0   \n",
       "\n",
       "   sent_neu      lda1  ...    dtv_25  review_len  crime_words  \\\n",
       "0     0.698  0.280112  ...  0.132382          67            0   \n",
       "1     0.728  0.000000  ...  0.108684          20            0   \n",
       "2     0.499  0.022306  ... -0.009348           8            0   \n",
       "3     0.680  0.000000  ... -0.249155          32            0   \n",
       "4     0.750  0.308462  ... -0.029153          19            0   \n",
       "\n",
       "   crime_words_perc  location_words  location_words_perc  business_words  \\\n",
       "0               0.0              14             0.208955              31   \n",
       "1               0.0               1             0.050000               5   \n",
       "2               0.0               0             0.000000               2   \n",
       "3               0.0               1             0.031250              13   \n",
       "4               0.0               4             0.210526               9   \n",
       "\n",
       "   business_words_perc  social_words  social_words_perc  \n",
       "0             0.462687             0           0.000000  \n",
       "1             0.250000             8           0.400000  \n",
       "2             0.250000             0           0.000000  \n",
       "3             0.406250             0           0.000000  \n",
       "4             0.473684             4           0.210526  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
